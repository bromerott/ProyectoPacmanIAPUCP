{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (10 points): Automated SMS spam filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data, look around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping the *real* first step (fleshing out specs, finding out what is it we want to be doing -- often highly non-trivial in practice!), let's download the dataset we'll be using in this demo. Go to https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection and download the zip file. Unzip it under `data` subdirectory. You should see a file called `SMSSpamCollection`, about 0.5MB in size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ ls -l data\n",
    "total 1352\n",
    "-rw-r--r--@ 1 kofola  staff  477907 Mar 15  2011 SMSSpamCollection\n",
    "-rw-r--r--@ 1 kofola  staff    5868 Apr 18  2011 readme\n",
    "-rw-r-----@ 1 kofola  staff  203415 Dec  1 15:30 smsspamcollection.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages** (see the `readme` file for more info):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [line.rstrip() for line in open('SMSSpamCollection.txt')]\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of texts is also sometimes called \"corpus\". Let's print the first ten messages in this SMS corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n",
      "(1, 'ham\\tOk lar... Joking wif u oni...')\n",
      "(2, \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")\n",
      "(3, 'ham\\tU dun say so early hor... U c already then say...')\n",
      "(4, \"ham\\tNah I don't think he goes to usf, he lives around here though\")\n",
      "(5, \"spam\\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, \\xc2\\xa31.50 to rcv\")\n",
      "(6, 'ham\\tEven my brother is not like to speak with me. They treat me like aids patent.')\n",
      "(7, \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\")\n",
      "(8, 'spam\\tWINNER!! As a valued network customer you have been selected to receivea \\xc2\\xa3900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.')\n",
      "(9, 'spam\\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030')\n"
     ]
    }
   ],
   "source": [
    "for message_no, message in enumerate(messages[:10]):\n",
    "    print (message_no, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is a [TSV](http://en.wikipedia.org/wiki/Tab-separated_values) (\"tab separated values\") file, where the first column is a label saying whether the given message is a normal message (\"ham\") or \"spam\". The second column is the message itself.\n",
    "\n",
    "This corpus will be our labeled training set. Using these ham/spam examples, we'll **train a machine learning model to learn to discriminate between ham/spam automatically**. Then, with a trained model, we'll be able to **classify arbitrary unlabeled messages** as ham or spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://radimrehurek.com/data_science_python/plot_ML_flow_chart_11.png)](http://www.astroml.org/sklearn_tutorial/general_concepts.html#supervised-learning-model-fit-x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of parsing TSV (or CSV, or Excel...) files by hand, we can use Python's `pandas` library to do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      ham  Even my brother is not like to speak with me. ...\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     spam  WINNER!! As a valued network customer you have...\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...\n",
      "10     ham  I'm gonna be home soon and i don't want to tal...\n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "13     ham  I've been searching for the right words to tha...\n",
      "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
      "16     ham                         Oh k...i'm watching here:)\n",
      "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
      "18     ham  Fine if thats the way u feel. Thats the way ...\n",
      "19    spam  England v Macedonia - dont miss the goals/team...\n",
      "20     ham          Is that seriously how you spell his name?\n",
      "21     ham    I‘m going to try for 2 months ha ha only joking\n",
      "22     ham  So ü pay first lar... Then when is da stock co...\n",
      "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
      "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
      "25     ham  Just forced myself to eat a slice. I'm really ...\n",
      "26     ham                     Lol your always so convincing.\n",
      "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
      "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
      "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
      "...    ...                                                ...\n",
      "5544   ham           Armand says get your ass over to epsilon\n",
      "5545   ham             U still havent got urself a jacket ah?\n",
      "5546   ham  I'm taking derek &amp; taylor to walmart, if I...\n",
      "5547   ham      Hi its in durban are you still on this number\n",
      "5548   ham         Ic. There are a lotta childporn cars then.\n",
      "5549  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5550   ham                 No, I was trying it all weekend ;V\n",
      "5551   ham  You know, wot people wear. T shirts, jumpers, ...\n",
      "5552   ham        Cool, what time you think you can get here?\n",
      "5553   ham  Wen did you get so spiritual and deep. That's ...\n",
      "5554   ham  Have a safe trip to Nigeria. Wish you happines...\n",
      "5555   ham                        Hahaha..use your brain dear\n",
      "5556   ham  Well keep in mind I've only got enough gas for...\n",
      "5557   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5558   ham  Yes i have. So that's why u texted. Pshew...mi...\n",
      "5559   ham  No. I meant the calculation is the same. That ...\n",
      "5560   ham                             Sorry, I'll call later\n",
      "5561   ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5562   ham                  Anything lor. Juz both of us lor.\n",
      "5563   ham  Get me out of this dump heap. My mom decided t...\n",
      "5564   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5565   ham                                Ard 6 like dat lor.\n",
      "5566   ham  Why don't you wait 'til at least wednesday to ...\n",
      "5567   ham                                       Huh y lei...\n",
      "5568  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570   ham               Will ü b going to esplanade fr home?\n",
      "5571   ham  Pity, * was in mood for that. So...any other s...\n",
      "5572   ham  The guy did some bitching but I acted like i'd...\n",
      "5573   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "messages = pandas.read_csv('SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "print (messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `pandas`, we can also view aggregate statistics easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ham</th>\n",
       "      <th>count</th>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">spam</th>\n",
       "      <th>count</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        message\n",
       "label                                                          \n",
       "ham   count                                                4827\n",
       "      unique                                               4518\n",
       "      top                                Sorry, I'll call later\n",
       "      freq                                                   30\n",
       "spam  count                                                 747\n",
       "      unique                                                653\n",
       "      top     Please call our customer service representativ...\n",
       "      freq                                                    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long are the messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message  length\n",
      "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
      "1   ham                      Ok lar... Joking wif u oni...      29\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
      "3   ham  U dun say so early hor... U c already then say...      49\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      61\n"
     ]
    }
   ],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))\n",
    "print (messages.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb13c69510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5574.000000\n",
       "mean       80.604593\n",
       "std        59.919970\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is that super long message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\"]\n"
     ]
    }
   ],
   "source": [
    "print (list(messages.message[messages.length > 900]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1085]\n"
     ]
    }
   ],
   "source": [
    "print (list(messages[messages.length > 900].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any difference in message length between spam and ham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAEQCAYAAAAXjQrJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb13982910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50, figsize=(12,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good fun, but how do we make computer understand the plain text messages themselves? Or can it under such malformed gibberish at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "Doing that requires essentially three steps, in the bag-of-words model:\n",
    "\n",
    "1. counting how many times does a word occur in each message (term frequency)\n",
    "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "3. normalizing the vectors to unit length, to abstract from the original text length (L2 norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector has as many dimensions as there are unique words in the SMS corpus.\n",
    "\n",
    "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "sms_tfidf = vectorizer.fit_transform(messages['message'].values)\n",
    "\n",
    "print(sms_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 (02 points): You must to analyze the new dataset and explain (a)its structure and (b) the meaning of the values.\n",
    "El nuevo dataset esta estructurado en una matriz de correspondencia de una tupla (n,t) a un valor f(n,t).\n",
    "Donde n es el numero del mensaje en el dataset, t es el numero asignado a alguna palabra, y f(n,t) es el TF-IDF calculado a partir de n y t.\n",
    "\n",
    "Asi, sms_tfidf.shape nos dice que hay 5574 mensajes, en los cuales hay 8713 diferentes palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a model, detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With messages represented as vectors, we can finally train our spam/ham classifier. This part is pretty straightforward, and there are many libraries that realize the training algorithms.\n",
    "The library sklearn.naive_bayes includes implementations of three Naïve Bayes classifiers\n",
    "- GaussianNB\n",
    "- MultinomialNB \n",
    "- BernoulliNB\n",
    "\n",
    "#### Question 2 (02 points): We will use MultinomialNB, why? \n",
    "\n",
    "Esto es debido a que el clasificador Multinomial es adecuado para valores discretos, como la cuenta de palabaras en un documento. Aunque utilizaremos un valor discreto (TF-IDF), este sigue resultando ser el más adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 (02 points): When are used the other two NB versions? \n",
    "El clasificador Gausiano es utilizado cuando podemos asumir que la distribucion de probabilidad es normal.\n",
    "Por otro lado, el clasificador Bernoulli es utilizado cuando se trabaja con valores booleanos como determinantes de nuestro algoritmo. (en este caso, TF-IDF no es booleano, sino continuo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "classifier1 = MultinomialNB()\n",
    "targets = messages['label'].values\n",
    "clf1 = classifier1.fit(sms_tfidf, targets)\n",
    "classifier2 = MultinomialNB(0,True,None)\n",
    "clf2 = classifier2.fit(sms_tfidf, targets)\n",
    "classifier3 = MultinomialNB(1.0,False,None)\n",
    "clf3 = classifier3.fit(sms_tfidf, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying our single random message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8668)\t0.266612317206\n",
      "  (0, 8523)\t0.5989041276\n",
      "  (0, 6113)\t0.613303401608\n",
      "  (0, 4376)\t0.440557210626\n"
     ]
    }
   ],
   "source": [
    "examples = ['You just won a prize!']\n",
    "example_vector = vectorizer.transform(examples)\n",
    "predictions = classifier2.predict(example_vector)\n",
    "\n",
    "print(example_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! You can try it with your own texts, too.\n",
    "\n",
    "A natural question is to ask, how many messages do we classify correctly overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9761\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4827    0\n",
      "1   133  614\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.99      4827\n",
      "       spam       1.00      0.82      0.90       747\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5574\n",
      "\n",
      "Accuracy: 0.9998\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4827    0\n",
      "1     1  746\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00      4827\n",
      "       spam       1.00      1.00      1.00       747\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5574\n",
      "\n",
      "Accuracy: 0.9840\n",
      "\n",
      "Confusion matrix:\n",
      "      0    1\n",
      "0  4772   55\n",
      "1    34  713\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99      4827\n",
      "       spam       0.93      0.95      0.94       747\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "all_predictions = clf1.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "all_predictions = clf2.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)\n",
    "\n",
    "all_predictions = clf3.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(messages['label'], all_predictions)\n",
    "cm = confusion_matrix(messages['label'], all_predictions)\n",
    "statistics = classification_report(messages['label'], all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (02 points): By default, MultinomialNB uses the Additive Laplace smoothing. Change the classifier to work without smoothing. Explain new results comparing with the default version.\n",
    "\n",
    "El clasificador sin Suavizado de Laplace resulta tener un Accuracy mayor (0.9998 en comparación de 0.9761).\n",
    "Esto es debido a que no estamos trabajando con un nuevo dataset para testar nuestra data. Envés, estamos utilizando el mismo dataset que usamos para entrenar al algoritmo para testearlo.\n",
    "\n",
    "Esto significa que no existirán nuevas palabras encontradas cuando exploremos nuestro test_dataset.\n",
    "La suavización de Laplace es utilizada para no dividir entre 0 cuando se encuentra una nueva palabra.\n",
    "\n",
    "De esta manera, al utilizar la suavizacion aditiva, estamos suavizando nuestros datos (perdiendo diferenciacion entre ellos) a cambio de ninguna ganancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 (02 points): How are computed the prior probabilities, with default parameters? Change the classifier to work with uniform prior probabilities. Explain new results comparing with the default version.\n",
    "Con parametros por default, las probabilidades a priori son calculadas. En la ultima ejecucion (classifier3), las probabilidades a priori fueron uniformes para cada dato.\n",
    "\n",
    "En comparacion con classfier1, este cambio aumenta el Accuracy. Esto es debido a que un calculo a priori de las probabilidades de cada clase depende que nuestros datos sigan algun tipo de distribucion fija. Sin embargo, como este no es el caso, es mejor no utilizar probabilidades a priori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (10 points): Automated mail spam detection\n",
    "\n",
    "* Repeat all previous stept, this time using a more complex corpus: mails dataset. Go to  http://www.aueb.gr/users/ion/data/enron-spam/ and download the Enron4 file, which is composed of two directories (ham and spam). You must to create the mail-class matrix in order to classify ham and spam mails, following the same steps of sms spam problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asd xx'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"asd\", \" xx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ham_folder = 'enron4/ham/'\n",
    "spam_folder = 'enron4/spam/'\n",
    "\n",
    "ham_files = [os.path.join(ham_folder, f) for f in os.listdir(ham_folder)]\n",
    "spam_files = [os.path.join(spam_folder, f) for f in os.listdir(spam_folder)]\n",
    "\n",
    "# Para abrir los files se necesita un encoding especial:\n",
    "##open(ham_files[3], encoding='iso-8859-7')\n",
    "\n",
    "##Crear nuestro directorio gigante de mensajes con spam y con ham\n",
    "mensajes=[]\n",
    "for archivo in ham_files:\n",
    "    doc=[]\n",
    "    for linea in codecs.open(archivo, encoding='iso-8859-7'):\n",
    "        doc= doc + list(linea.rstrip())\n",
    "\n",
    "    doc= \"\".join(doc)\n",
    "    mensajes.append(doc)\n",
    "for archivo in spam_files:\n",
    "    doc=[]\n",
    "    for linea in codecs.open(archivo, encoding='iso-8859-7'):\n",
    "        doc= doc + list(linea.rstrip())\n",
    "\n",
    "    doc= \"\".join(doc)\n",
    "    mensajes.append(doc)\n",
    "##Crear un arreglo dondo los 1500 primeros son ham y 4500 son spam\n",
    "labels=[]\n",
    "for _ in range(1500):\n",
    "    labels.append(\"ham\");\n",
    "for _ in range(4500):\n",
    "    labels.append(\"spam\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 95038)\n"
     ]
    }
   ],
   "source": [
    "#Datos a vectores\n",
    "vectorizer = TfidfVectorizer()\n",
    "sms_tfidf = vectorizer.fit_transform(mensajes)\n",
    "print(sms_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Entrar modelo usando clasificador multinomial sin suavizacion, dado que lo probaremos en el mismo dataset con el que\n",
    "#lo entrenaremos\n",
    "targets = labels\n",
    "classifier = MultinomialNB(0,True,None)\n",
    "clf = classifier.fit(sms_tfidf, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a44e0e2c7e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Probar modelo con ejemplitos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'You just won a prize!'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexample_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Probar modelo con ejemplitos\n",
    "examples = ['You just won a prize!']\n",
    "example_vector = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_vector)\n",
    "\n",
    "print(example_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995\n",
      "\n",
      "Confusion matrix:\n",
      "      0     1\n",
      "0  1500     0\n",
      "1     3  4497\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00      1500\n",
      "       spam       1.00      1.00      1.00      4500\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conseguir data del algoritmo, probandolo en el mismo dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "all_predictions = clf.predict(sms_tfidf)\n",
    "accuracy = accuracy_score(labels, all_predictions)\n",
    "cm = confusion_matrix(labels, all_predictions)\n",
    "statistics = classification_report(labels, all_predictions)\n",
    "\n",
    "print('Accuracy: %.4f\\n' % accuracy)\n",
    "print('Confusion matrix:\\n%s\\n' % pandas.DataFrame(cm))\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy: 0.9395\n",
    "\n",
    "Confusion matrix:\n",
    "       0       1\n",
    "0  14414    6305\n",
    "1   1078  100292\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        ham       0.93      0.70      0.80     20719\n",
    "       spam       0.94      0.99      0.96    101370\n",
    "\n",
    "avg / total       0.94      0.94      0.94    122089"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
